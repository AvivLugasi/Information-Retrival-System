applied
sciences
Article

Explainable Artificial Intelligence Enabled TeleOphthalmology
for Diabetic Retinopathy Grading and Classification
Marwa Obayya 1 , Nadhem Nemri 2 , Mohamed K. Nour 3 , Mesfer Al Duhayyim 4, *, Heba Mohsen 5 ,
Mohammed Rizwanullah 6 , Abu Sarwar Zamani 6 and Abdelwahed Motwakel 6
1

2

3

4

5

6

*

Citation: Obayya, M.; Nemri, N.;
Nour, M.K.; Al Duhayyim, M.;
Mohsen, H.; Rizwanullah, M.; Sarwar
Zamani, A.; Motwakel, A.
Explainable Artificial Intelligence
Enabled TeleOphthalmology for
Diabetic Retinopathy Grading and
Classification. Appl. Sci. 2022, 12,
8749. https://doi.org/10.3390/
app12178749
Academic Editor: Grazia Maugeri
Received: 5 August 2022
Accepted: 29 August 2022
Published: 31 August 2022
Publisherâ€™s Note: MDPI stays neutral
with regard to jurisdictional claims in
published maps and institutional affiliations.

Copyright: Â© 2022 by the authors.
Licensee MDPI, Basel, Switzerland.
This article is an open access article
distributed under the terms and
conditions of the Creative Commons
Attribution (CC BY) license (https://
creativecommons.org/licenses/by/
4.0/).

Department of Biomedical Engineering, College of Engineering, Princess Nourah bint Abdulrahman
University, P.O. Box 84428, Riyadh 11671, Saudi Arabia
Department of Information Systems, College of Science & Art, Mahayil, King Khalid University,
Abha 62529, Saudi Arabia
Department of Computer Sciences, College of Computing and Information System,
Umm Al-Qura University, Mecca 24382, Saudi Arabia
Department of Computer Science, College of Sciences and Humanities-Aflaj,
Prince Sattam bin Abdulaziz University, Al-Kharj 16278, Saudi Arabia
Department of Computer Science, Faculty of Computers and Information Technology,
Future University in Egypt, New Cairo 11835, Egypt
Department of Computer and Self Development, Preparatory Year Deanship,
Prince Sattam bin Abdulaziz University, Al-Kharj 16278, Saudi Arabia
Correspondence: m.alduhayyim@psau.edu.sa

Abstract: Recently, Telehealth connects patients to vital healthcare services via remote monitoring,
wireless communications, videoconferencing, and electronic consults. By increasing access to specialists and physicians, telehealth assists in ensuring patients receive the proper care at the right
time and right place. Teleophthalmology is a study of telemedicine that provides services for eye
care using digital medical equipment and telecommunication technologies. Multimedia computing
with Explainable Artificial Intelligence (XAI) for telehealth has the potential to revolutionize various
aspects of our society, but several technical challenges should be resolved before this potential can be
realized. Advances in artificial intelligence methods and tools reduce waste and wait times, provide
service efficiency and better insights, and increase speed, the level of accuracy, and productivity
in medicine and telehealth. Therefore, this study develops an XAI-enabled teleophthalmology for
diabetic retinopathy grading and classification (XAITO-DRGC) model. The proposed XAITO-DRGC
model utilizes OphthoAI IoMT headsets to enable remote monitoring of diabetic retinopathy (DR)
disease. To accomplish this, the XAITO-DRGC model applies median filtering (MF) and contrast
enhancement as a pre-processing step. In addition, the XAITO-DRGC model applies U-Net-based
image segmentation and SqueezeNet-based feature extractor. Moreover, Archimedes optimization
algorithm (AOA) with a bidirectional gated recurrent convolutional unit (BGRCU) is exploited for
DR detection and classification. The experimental validation of the XAITO-DRGC method can be
tested using a benchmark dataset and the outcomes are assessed under distinct prospects. Extensive
comparison studies stated the enhancements of the XAITO-DRGC model over recent approaches.
Keywords: telemedicine; diabetic retinopathy; fundus images; deep learning; teleophthalmology

1. Introduction
The term â€œtelemedicineâ€ was defined in the 1970s by Strehle and Shabde as â€œhealing
at a distanceâ€. The World Health Organization (WHO) presented a standard meaning of
telemedicine as â€œthe delivery of health care services, where distance becomes a critical factor,
by every healthcare expert by making use of information and communication technology
(ICT) for interchanging validated data for prognosis, medication and preventing injuries
and diseaseâ€ [1]. Telemedicine depends on ICT, termed a â€œdifferent set of technical tools and

Appl. Sci. 2022, 12, 8749. https://doi.org/10.3390/app12178749

https://www.mdpi.com/journal/applsci

Appl. Sci. 2022, 12, 8749

2 of 18

sources utilized for creating, transmitting, exchanging or sharing, storing, information [2].
Such resources and technological tools involve live broadcasting technology (television,
webcasting, and radio), recorded broadcasting technology (podcasting, video and audio
players, and memory gadgets), telephony (mobile or fixed, satellite, video-conferencing),
and the internet (emails, websites, and blogs)â€. A creative grouping of screening with the
help of Optical Coherence Tomography (OCT), fundus cameras, and other gadgets with
telemedicine escorted in the period of teleophthalmology can be implemented in non-eye
care backgrounds and in ophthalmology offices, which include primary care workplaces [3].
This can be possible by appropriate follow-up eye care and remote grading. Developing
global interest in the usage of telemedicine in screening for diabetic retinopathy (DR)
caused the emergence of several journals during the past few years [4].
Diabetes mellitus was a very expensive and pandemic chronic ailment. It affects nearly
4.15 billion people across the world, responsible for 12% of the global health expenses, and
even so, 1 in 2 people were untreated and undiagnosed [5]. Subsequently, life-threatening
complexities because of diabetes mellitus, namely cardiomyopathy, neuropathy, strokes,
retinopathy, and nephropathy have hiked across many countries. Today, caregivers and
patients will stay on a query relating to diabetes management [6]. For instance, frequent
diagnoses and offering essential advice for patients in self-management were needed for the
prevention of acute terrible complexities and to reduce the danger of life-long conditions [7].
The surge of a higher volume of real-world data collected at the time of medications has
generated incredible enthusiasm in diabetic care. Among them, imagery reports present a
great effect on developing new insights and disturb the present understanding of diabetic
care. Currently, medical imaging is mostly utilized for diagnosing, prioritizing treatment,
and evaluating replies to medications in modern medicine [8]. The main reason was the
work pressure of a health care professional surges significantly because of a huge number
of patients indulging in population screening and thus, patients are waiting in a lengthy
queue [9]. Artificial intelligence (AI) was increasingly automating health care practices and
provides high precision, satisfaction, and efficiency [10]. With the recent progression in
digitalized data acquisition, machine learning (ML), and computer vision (CV), AI was
diffusing into medical decision-making processes that are formerly scrutinized below the
direct supervising of human professionals.
This study develops an XAI-enabled teleophthalmology for diabetic retinopathy grading and classification (XAITO-DRGC) model. The proposed XAITO-DRGC model uses
median filtering (MF) and contrast enhancement as a pre-processing step. In addition,
the XAITO-DRGC model applies U-Net-based image segmentation and SqueezeNet-based
feature extractor. Moreover, Archimedes optimization algorithm (AOA) with a bidirectional
gated recurrent convolutional unit (BGRCU) is exploited for DR detection and classification. The experimental validation of the XAITO-DRGC model is tested using a benchmark
dataset and the results are assessed under distinct aspects.
2. Related Works
Wijesinghe et al. [11] suggest a prototype that includes an independent system named
Intelligent Diabetic Assistant (IDA), that determines the prognosis and the treatment prioritizing relies on the observation manifested on a screen. The IDA comprises a knowledgerelated module for a severity level-related classifier, and clinical decision support. In [12],
an ensemble-based ML method containing ML techniques such as Logistic Regression
(LR), Random Forest (RF), Adaboost, KNN, and Decision Tree (DT) can be tested on the
DR dataset. In the initial step, normalization can be performed on the DR dataset by the
min-max normalization technique. Hacisoftaoglu et al. [13] introduced an automatic DR
detection technique for smartphone-related retinal images by utilizing the DL technique
with the ResNet50 network. This work primarily used familiar ResNet50, AlexNet, and
GoogLeNet structures by making use of the transfer learning (TL) method. Secondly, such
structures are retrained with retinal images from numerous datasets involving Messidor-2,
EyePACS, IDRiD, and Messidor for investigating the impact of utilizing images from the

Appl. Sci. 2022, 12, 8749

DL technique with the ResNet50 network. This work primarily used familiar ResNet50,
AlexNet, and GoogLeNet structures by making use of the transfer learning (TL) method.
Secondly, such structures are retrained with retinal images from numerous datasets involving Messidor-2, EyePACS, IDRiD, and Messidor for investigating the impact of utilizing images from the cross, multiple, and single datasets. Thirdly, the suggested
3 of 18 ResNet50 method can be implied to smartphone-related synthetic images for exploring the
DR detection accuracy of smartphone-related retinal imaging systems.
In [14],
a method
for automatic
ofsuggested
DR was suggested
with thecan
help
cross,
multiple,
and single
datasets. detection
Thirdly, the
ResNet50 method
be of
im-a low
plied to smartphone-related
images
exploringConvolutional
the DR detectionNeural
accuracy
of
complexity
image processingsynthetic
approach
and for
a modified
Network
smartphone-related
retinal
imaging
systems.
(CNN) having superior precision for helping an ophthalmologist via identification of varIn retina
[14], a method
automatic
of project
DR wasasuggested
with the help
of a low via
iation in
features.forPapon
and detection
Islam [15]
robust diagnostic
mechanism
complexity
image
processing
approach
and
a
modified
Convolutional
Neural
Network
a compilation of state-of-the-art deep learning (DL) methods for automatic DR severity
(CNN) having superior precision for helping an ophthalmologist via identification of
detection. The idea of deep CNNs was used and revolutionized various branches of CV
variation in retina features. Papon and Islam [15] project a robust diagnostic mechanism
such
medical imaging.
Fayemiwo
et al.
[16] provided
an approach
thatDR
directly
classiviaas
a compilation
of state-of-the-art
deep
learning
(DL) methods
for automatic
severity
fiesdetection.
and identifies
the of
DRdeep
severity
in was
digitalized
fundus
images by
employing
CNN.
The idea
CNNs
used and
revolutionized
various
branches
of The
methods
employed
are
CNN
built
and
integrated
with
Keras.
The
dataset
which
is
trained
CV such as medical imaging. Fayemiwo et al. [16] provided an approach that directly
is divided
kinds;
are categorical
and binary
further
trained
with or
classifiesinto
and two
identifies
thethey
DR severity
in digitalized
fundusdatasets
images by
employing
CNN.
The methods
employedand
are their
CNNresults
built and
with Keras. The dataset which is
without
pre-processing
areintegrated
compared.
trained
is divided
intoDR
twoclassification
kinds; they aremodels
categorical
binary
datasetsitfurther
Although
diverse
existand
in the
literature,
is still trained
required to
withthe
or without
pre-processing
theirincessant
results aredeepening
compared. of the model, the number of
boost
classifier
results. Dueand
to the
Although diverse DR classification models exist in the literature, it is still required to
parameters
of DL models gets raised quickly which leads to model overfitting. At the
boost the classifier results. Due to the incessant deepening of the model, the number of
same time, different hyperparameters have a significant impact on the efficiency of the
parameters of DL models gets raised quickly which leads to model overfitting. At the same
CNN
model.
Particularly,
hyperparameters
such as
epochoncount,
batch size,
andCNN
learning
time,
different
hyperparameters
have a significant
impact
the efficiency
of the
rate
selection
are
essential
to
attain
an
effectual
outcome.
Since
the
trial
and
error
method
model. Particularly, hyperparameters such as epoch count, batch size, and learning rate
forselection
hyperparameter
tuning
is aan
tedious
and
erroneous
this
work,
we employ
are essential
to attain
effectual
outcome.
Sinceprocess,
the trialin
and
error
method
for
thehyperparameter
AOA algorithm
for the
selection
of the
BGRCU
model.
tuning
is aparameter
tedious and
erroneous
process,
in this
work, we employ the
AOA algorithm for the parameter selection of the BGRCU model.

3. The Proposed Model

3. The Proposed Model

In this article, a novel XAITO-DRGC technique was devised for the detection and
In this article, a novel XAITO-DRGC technique was devised for the detection and
classification
of DR. Initially, the XAITO-DRGC model applies MF and contrast enhanceclassification of DR. Initially, the XAITO-DRGC model applies MF and contrast enhancement
as
a
pre-processing
addition,the
theXAITO-DRGC
XAITO-DRGC
model
applies
U-Net-based
ment as a pre-processing step.
step. In
In addition,
model
applies
U-Net-based
image
segmentation
SqueezeNet-based
feature
extractor.
Finally,
with BGRCU
image
segmentation and
and SqueezeNet-based
feature
extractor.
Finally,
AOA AOA
with BGRCU
is
is exploited
for
DR
detection
and
classification
where
the
AOA
assist
in
optimal
hyperpaexploited for DR detection and classification where the AOA assist in optimal hyperparameter tuning
of the
BGRCU
model.
FigureFigure
1 depicts
the block
diagram
the XAITO-DRGC
rameter
tuning
of the
BGRCU
model.
1 depicts
the
block of
diagram
of the XAITOalgorithm.
DRGC
algorithm.

Figure
1. 1.
Block
diagram
approach.
Figure
Block
diagramof
ofthe
the XAITO-DRGC
XAITO-DRGC approach.

Appl. Sci. 2022, 12, 8749

4 of 18

The proposed architecture comprises three basic mechanisms to empower an ophthalmologist in the telemedicine environment while collaborating with AI-based healthcare
assistive expertise:
1.

2.

3.

A wearable head-mounted camera OphthoAI Internet of Medical Things (IoMT)
headset with DL applications for DR disease severity diagnosis. This application
enables us to take fresh retinal fundus images of eyes that are later transferred through
the internet to a centralized position protected behindhand a firewall. The headset
assists inference in the cloud backend with AI and data analytics services or local
inference with an embedded-AI technique. User information is locally stored with
encryption.
A cloud computing platform that serves and manages a connection to an AI engine
for predicting disease progression, a single OphthoAI IoMT headset, secured patients
cloud storage drive, metering and monitoring of computing resources, secured communication of fundus representations, etc. The service can be managed by a cloud IoT
system manager and IoT-assisted healthcare service directory.
An ophthalmologist dashboard with a secured multi-tenant cloud backend, providing
privacy-aware role-based access control to resources and personal information. Secured multitenancy confirms users do not pose a risk to each other in terms of misuse,
privacy violation, or data loss.

3.1. Image Pre-Processing
At the initial stage, the XAITO-DRGC model applies MF and contrast enhancement as
a pre-processing step. The MF technique adopts a non-linear approach for noise exclusion
from scaled input images [17]. It functions by sliding pixel by pixel, replacing every pixel
value with a median value of adjacent pixels. The window pattern having a size of 3 Ã— 3 can
be utilized to slide pixel by pixel over the neighbors in a scaled input image. The calculation
of the median is conducted by sorting every pixel value primarily in arithmetical order
in the window paradigm and interchanging the pixel values with the central pixel value.
The histogram equalization technique can be implied for enhancing the contrast of the
scaled input image by making use of its histogram. The procedure is done through the
distribution of pixel intensity values that were appearing frequently and thus, low contrast
regions of an image obtain high contrast.
3.2. Image Segmentation
Next to image pre-processing, the XAITO-DRGC model applies U-Net-based image
segmentation. U-Net is initially established for medicinal image understanding and segmentation [18]. It is a vast application from the area and is an important structure of
the medicinal image automation society. The infrastructure of this network contains two
important parts namely contractive and expansive. The contracting direction contains
many patches of convolutional with a filter of size 3 Ã— 33 Ã— 3 and unity strides from
both paths, then a rectified linear unit (ReLU) layer. This direction extracts the important
features of input and outcomes from a feature vector of a particular length. The second
direction pulls data in the contractive direction using copy and crop, and in the feature
vector using up-convolution creates, with a succeeding function, a resultant segmentation
map. An important element of this structure is the procedure connecting the 1st and 2nd
directions composed. This connection permits the network for attaining extremely accurate
data in the contractive path, creating the segmentation mask nearby the projected outcome.
3.3. Feature Extraction
At this stage, the segmented images are passed into the SqueezeNet model to produce
feature vectors. Generally, the CNN comprises a pooling layer, full connection layer,
and convolutional layer. At first, the feature is extracted using multiple convolutions
and pooling layers. Next, the feature mapping from the final convolutional layers is
transformed into a one-dimensional vector. At last, the output layer classifies the input

Appl. Sci. 2022, 12, x FOR PEER REVIEW
Appl. Sci. 2022, 12, 8749

5 of 18
5 of 18

transformed into a one-dimensional vector. At last, the output layer classifies the input
image. The network reduces the square variance amongst the predictable output and clasimage.
The
networkand
reduces
thethe
square
variance
amongst
theofpredictable
output
andthe
sification
outcomes
changes
weight
variable
by means
BP. The neuron
in all
classification
outcomes
and
changes
the
weight
variable
by
means
of
BP.
The
neuron
in
layers are well-arranged in three dimensions: depth, height, and width, whereby depth
all
the
layers
are
well-arranged
in
three
dimensions:
depth,
height,
and
width,
whereby
represents the amount of input feature mappings or channel amount of input image, and
depth
therefers
amount
of input
mappings
channel amount
input image,
heightrepresents
and width
to the
size feature
of a neuron.
The or
convolution
layer of
contains
several
and height and width refers to the size of a neuron. The convolution layer contains
convolutional filters and extracts features from the image through the convolutional techseveral convolutional filters and extracts features from the image through the convolutional
nique. The convolutional filter of the existing layer convoluted the input feature mapping
technique. The convolutional filter of the existing layer convoluted the input feature
to extract local features and accomplishes the output feature mapping. Next, the nonlinear
mapping to extract local features and accomplishes the output feature mapping. Next,
feature mapping is accomplished by the activation function. The pooling layer, or subthe nonlinear feature mapping is accomplished by the activation function. The pooling layer,
sampling layer, was behind the convolution layers. It implements a down-sampling
or subsampling layer, was behind the convolution layers. It implements a down-sampling
methodand
andhas
hasaaparticular
particularvalue
valueasasoutput
outputinina acertain
certainregion.
region.
method
As
the
variable
count
for
AlexNet
and
VGGNet
increases,
the
SqueezeNet
network
As the variable count for AlexNet and VGGNet increases, the
SqueezeNet
network
architecture
was
introduced
that
has
the
lowest
variable
while
maintaining
accuracy
[19].
architecture was introduced that has the lowest variable while maintaining accuracy [19].
The fire
firemodule
modulebecomes
becomesthe
theessential
essentialmodule
moduleininSqueezeNet,
SqueezeNet,asaswell
wellasasitsitsarchitecture,
architecture,
The
as
given
in
Figure
2.
This
module
can
be
divided
into
Expand
and
Squeeze
architecture.
as given in Figure 2. This module can be divided into Expand and Squeeze architecture.
The
1
Ã—
1
convolution
layer
received
considerable
attention
in
the
network
architecture.
The 1 Ã— 1 convolution layer received considerable attention in the network architecture.
The work
workexplains
explainsfrom
fromthe
theperceptive
perceptiveofofcross
crosschannel
channelpooling
poolingwhereas
whereasmultilayer
multilayerperperThe
ceptron (MLP)
(MLP) was equivalent to
ceptron
to the
thecascaded
cascadedcross
crosschannel
channelparametric
parametricpooling
poolinglayer
layerbehind the
integrationover
overthe
thechannel
channeland
and
linear
behind
thetraditional
traditionalkernel,
kernel,thus
thus achieving
achieving data integration
linear
incorporation of
of several
severalfeature
featuremaps.
maps.Once
Oncethe
theamount
amountofofinput
inputand
andoutput
output
channels
incorporation
channels
were
large.
Then,
adding
1Ã—
to to
weregreater,
greater,the
theconvolutional
convolutionalkernels
kernelsbecome
become
large.
Then,
adding
1 Ã—1 convolutions
1 convolutions
every
well
asas
thethe
every single
single inception
inceptionmechanism
mechanismreduces
reducesthe
thenumber
numberofofinput
inputchannels,
channels,asas
well
complexity
add
1Ã—
complexity operation
operationand
andconvolution
convolutionkernel
kernelvariables
variablesare
aredecreased.
decreased.Lastly,
Lastly,
add
1 1Ã— 1
convolutions
increase the
the feature
featureextraction
extractionand
andthe
thenumber
number
channels.
Once
convolutions to
to increase
ofof
channels.
Once
the the
samsampling
reduction
method
can
be
delayed,
a
larger
activation
graph
was
provided
to
the
pling reduction method can be delayed, a larger activation graph was provided to the
convolution
thethe
larger
activation
graph
preserves
further
data and
convolutionlayer,
layer,whereby
whereby
larger
activation
graph
preserves
further
dataprovides
and probetter
classification
performance.
vides better classification performance.

Figure2.2. Structure
Structureof
ofSqueezeNet.
SqueezeNet.
Figure

Appl. Sci. 2022, 12, 8749

6 of 18

3.4. Image Classification
In the final stage, the BGRCU is exploited for DR detection and classification. Gated
recurrent unit (GRU) is making all the recurrent units for adaptably capture dependency of
distinct time scales. Like the long short term memory (LSTM), the GRU is a gate unit that
modulates the flow of data inside the memory [20], but without taking a discrete memory
cell. The input to GRU in step t is D dimension vector xt âˆˆ RD . The hidden vector sequence
h1T := h1 , . . . , h T was computed as iterating the subsequent formulas in t = 1, . . . , T:
zt = Ïƒ (Wz xt + Uz htâˆ’1 + bz )
rt = Ïƒ (Wr xt + Ur htâˆ’1 + br )
h = Ïƒ (Wh xt + Uh (rt E

h t âˆ’1 ) + bh )

h t = (1 âˆ’ z t ) h t âˆ’1 + z t h t
The activation has been collected of the update gate zt , reset gate rt , candidate gate
h, and resultant activation ht . W(â€¢) , U(â€¢) , and b(â€¢) represent the suitable sized matrix and
bias. The symbol Ïƒ represents the sigmoid activation and
denotes the elementwise
multiplication. The BiGRU processes data from both directions with forward as well as
backward hidden layers. Related to the unidirectional case the number of free parameters
doubles. The outcome of both directions is then concatenated from the outcome.
â†’T

Assume h 1 remain the forwarding outcome of BGRU with procedure the input
â†T

order x1T with t = 1, . . . , T and consider h 1 to be the equivalent backward outcome
with processing the input order in the reverse direction with t = T, . . . , 1. The outcome h1T of BGRU is the step-wise concatenation of forward as well as backward outputs
â†’

â†

h t := ( h t , h t ).
An input to Gated Recurrent Convolutional Unit (GRCU) with C channel and input
dimensional D is an order x1T of vectors xt âˆˆ RCÃ— D . The hidden vector order h1T has been
calculated by iterating the subsequent formulas in t = 1, . . . , T:
zt = Ïƒ (Wz âˆ— xt + pool (Uz âˆ— htâˆ’1 ) + bz )
rt = Ïƒ (Wr âˆ— xt + pool (Ur âˆ— htâˆ’1 ) + br )
ht = Ïƒ (Wh âˆ— xt + pool (Uh âˆ— (rt

htâˆ’1 )) + bh )

h t = (1 âˆ’ z t ) h t âˆ’1 + z t h

R F Ã—C Ã— L

W(â€¢) âˆˆ
and U(â€¢) âˆˆ RFÃ— FÃ— L are F features map of length L. The max-pooling
functions also take length L and b(â€¢) âˆˆ RF are the bias. The GRCU utilizes a similar gating
infrastructure as the BGRU, then every fully connected (FC) matrix multiplication was
replaced with a convolutional matrix function afterward a max-pooling function with a
similar filter length. Integrating GRCU as well as bidirectional recurrent neural network
(RNN) outcomes from the BGRCU that were determined analogously to BGRU.
In this study, the AOA assists in optimal hyperparameter tuning of the BGRCU model.
AOA is a technique simulated by physics, in further detail Archimedesâ€™ law. This technique
was established by Fatma Hashim in 2020 and goes into the class of meta-heuristics [21].
In the procedure of AOA, the upgrade of density and volume has been recognized for
changing the acceleration dependent upon the collision model amongst objects that play a
vital role from determine a new place of present solutions. The common steps of AOA are
explained as:

Appl. Sci. 2022, 12, 8749

7 of 18

The initialized procedure purposes for initializing arbitrarily the real population which
comprises N objects utilized in Equation (1). Moreover, all the objects are considered as
density ( Di ), volume (Vi ), and acceleration (Î“i ) that are randomly determined by the
subsequent equation:


Oi = OiMin + r1 Ã— OiMax âˆ’ OiMin ; i = 1, 2, . . . , N
(1)
Di = r 2

(2)

Vi = r3


(3)


Î“i = Î“Max
+ r4 Ã— Î“Max
âˆ’ Î“Min
; i = 1, 2, . . . , N
i
i
i

(4)

Let Oi be the ith object, and OiMin and OiMax refers to the maximum and minimum
bounds of the searching space, correspondingly. r1 , r2 , r3 , and r4 denotes random vector
lies between [0, 1] Dim . In the updating of volume and density, the values of density and
volume for every object were upgraded by the control of the optimal density and volume
as follows:

Dit+1 = D t + s1 Ã— DBest âˆ’ Dit
(5)

Vit+1 = Vit + s2 Ã— VBest âˆ’ Vit
(6)
From the equation, s1 , s2 refers to numbers lying within zero and one. Next, the collision between objects happened till attaining the equilibrium state. The key role of
the transfer function ( Tc ) is to shift from exploration to exploitation modes, determined
as follows:


tâˆ’T
Tc = exp
(7)
T
The Tc exponentially increases over time until obtaining 1. t refers to the existing
iteration, whereas T represents the maximal iteration count. Similarly, the reduction of the
density scalar ds in AOA permits to discover an optimum solution [22]:
  

t
tâˆ’T
t +1
âˆ’
(8)
ds = exp
T
T
In the exploration phase, the collision between agents is appeared by randomly selecting material ( Mr ). Therefore, the update of the acceleration object is employed if the
transfer function value was lesser or equivalent to 0.5.
Î“it+1 =

D Mr + VMr Ã— Î“ Mr
Dit+1 Ã— Vit+1

(9)

In the exploitation, the collision between agents was not realized. Therefore, the update
of the acceleration object can be employed if the transfer coefficient values are higher
than 0.5.
D
+V Ã—Î“
Î“it+1 = Best t+1 Best t+1 Best
(10)
Di Ã— Vi
In Equation (10), Î“ Best represents the acceleration of the optimum object OBest . During
normalization, we normalize the acceleration to define the rate of change as follows:
+1
Î“riâˆ’
norm = Î± Ã—

Î“ri +1 âˆ’ Î“Min
+Î²
Î“Max âˆ’ Î“Min

(11)

+1
In Equation (11), Î± and Î² are set as 0.9 and 0.1, correspondingly. Î“itâˆ’
norm illustrates
the proportion of steps adapted by every agent. A low acceleration value specifies that the
object was working under the exploitation mode; or else, the object was working under
an exploration mode. For the exploration stage ( Tc â‰¤ 0.5), the location of the ith object in

Appl. Sci. 2022, 12, 8749

8 of 18

the t + 1 iteration is adapted using the following equation, where the object location is
upgraded in the exploitation stage ( Tc > 0.5).

+1
t
Oit+1 = Oit + c1 Ã— r5 Ã— Î“itâˆ’
(12)
norm Ã— ds Ã— Orand âˆ’ Oi
where c1 is set as 2.
+1
t
Oit+1 = OtBest + F Ã— c2 Ã— r6 Ã— Î“itâˆ’
norm Ã— ds Ã— Î´ Ã— OBest âˆ’ Oi



(13)

where c2 is set as 6. F is applied for flagging which controls search direction:

F=

+1 i f Î¶ â‰¤ 0.5
âˆ’1 i f Î¶ > 0.5

(14)

where Î¶ = 2 Ã— rand âˆ’ 0.5.
Lastly, the novel population is estimated via score index Sc to define the best object
OBest and the best additive data involving DBest , VBest , and Î“ Best .
The AOA method makes a derivation of a fitness function for attaining advanced
classifier performances. It sets a positive numeral for indicating the superior performance
of the candidate solutions. In this article, the reduction of the classifier error rate can be
assumed as the fitness function, as presented below in Equation (15).
f itness( xi ) = Classi f ierErrorRate( xi )=

number o f misclassi f ied samples
âˆ— 100
Total number o f samples

(15)

4. Experimental Validation
The experimental validation of the XAITO-DRGC model is tested using two datasets.
Table 1 depicts the detailed description of two datasets. The DDR dataset [23] comprises
13,673 fundus images obtained at a 45â—¦ field of view (FOV). Among these, there were
1151 ungradable images, 6266 normal images, and 6256 DR images. The APTOS 2019
Kaggle dataset [24] has 3662 retina images with various image sizes. The dataset can
be classified into five DR stages. Moreover, 1805 of the images are normal and 1857 are
DR images.
Table 1. Dataset details.
Class

APTOS 2019

DDR Dataset

Normal

361

1253

Mild

74

126

Moderate

200

895

Severe

39

47

Proliferative

59

182

Total No. of Images

733

2503

Figure 3 illustrates the confusion matrices given by the XAITO-DRGC model on
the APTOS 2019 dataset. On the entire dataset, the XAITO-DRGC model has identified
344 samples as normal, 59 samples as mild, 188 samples as moderate, 21 samples as severe,
and 42 samples as proliferative. In addition, on 70% of training (TR) data, the XAITO-DRGC
method has identified 243 samples as normal, 43 samples as mild, 132 samples as moderate,
12 samples as severe, and 26 samples as proliferative. Also, on 30% of testing (TS) data,
the XAITO-DRGC technique has identified 101 samples as normal, 16 samples as mild,
56 samples as moderate, 9 samples as severe, and 16 samples as proliferative.

Appl.
FOR PEER REVIEW
Appl. Sci.
Sci. 2022,
2022, 12,
12, x8749

9 9ofof 18
18

Figure
of the
the XAITO-DRGC
XAITO-DRGCapproach
approachunder
underthe
theAPTOS
APTOS2019
2019
dataset
enFigure 3.
3. Confusion
Confusion matrices
matrices of
dataset
(a)(a)
entire
tire
dataset,
(b)
70%
of
TR
data,
and
(c)
30%
of
TS
data.
dataset, (b) 70% of TR data, and (c) 30% of TS data.

Table
Table 2 and Figure 4 provide an overall classification
classification output
output of
of the
the XAITO-DRGC
XAITO-DRGC
model
on the
theAPTOS
APTOS2019
2019
dataset.
experimental
values
notified
thatXAITO-DRGC
the XAITOmodel on
dataset.
TheThe
experimental
values
notified
that the
DRGC
model
has
shown
enhanced
results
under
distinct
aspects.
For
instance,
with
the
model has shown enhanced results under distinct aspects. For instance, with the
entire
entire
dataset,
the XAITO-DRGC
has offered
an average
ofprec
95.69%,
ğ‘ğ‘Ÿğ‘’ğ‘
dataset,
the XAITO-DRGC
model model
has offered
an average
accuy ofğ‘ğ‘ğ‘ğ‘¢
95.69%,
n of 86.04%,
of y78.81%,
ğ‘ ğ‘ğ‘’ğ‘andofFscore
96.59%,
and ğ¹ Meanwhile,
of 81.69%.
of
86.04%,
ğ‘Ÿğ‘’ğ‘ğ‘ spec
reca
of 96.59%,
of 81.69%.
withMeanwhile,
70% of TR with
data,
l of 78.81%,
the XAITO-DRGC
has provided
average
accuan
95.56%,ğ‘ğ‘ğ‘ğ‘¢
precn of
of 95.56%,
86.59%,
70%
of TR data, theapproach
XAITO-DRGC
approachanhas
provided
average
y of
recal ofof77.01%,
96.42%,
and
Fscoreofof96.42%,
80.13%.and
Eventually,
30%Eventually,
of TS data,
86.59%,spec
ğ‘Ÿğ‘’ğ‘ğ‘
77.01%,
ğ‘ ğ‘ğ‘’ğ‘
ğ¹
ofwith
80.13%.
ğ‘ğ‘Ÿğ‘’ğ‘
y of of
the
XAITO-DRGC
algorithm
has
rendered
an
average
accu
of
96%,
prec
of
86.48%,
recal
y
n ğ‘ğ‘ğ‘ğ‘¢ of 96%,
with 30% of TS data, the XAITO-DRGC algorithm has rendered
an average
of
83.14%,
spec
of
96.97%,
and
F
of
84.52%.
y ğ‘Ÿğ‘’ğ‘ğ‘ of 83.14%,
scoreğ‘ ğ‘ğ‘’ğ‘ of 96.97%, and ğ¹
of 84.52%.
ğ‘ğ‘Ÿğ‘’ğ‘ of 86.48%,

Appl. Sci. 2022, 12, 8749

10 of 18

Appl. Sci. 2022, 12, x FOR PEER REVIEW

10 of 18

Table 2. Result analysis of the XAITO-DRGC approach with various measures on the APTOS 2019
dataset.
Table
2. Result analysis
of the XAITO-DRGC
on the APTOS
2019
Labels
Accuracy
Precisionapproach with
Recallvarious measures
Specificity
F-Score
dataset.
Entire Dataset

Labels
Normal
Mild

Normal
Moderate
Mild
Severe
Moderate
Proliferative
Severe
Average
Proliferative
Average
Normal
Mild
Normal
Moderate
Mild

Moderate
Severe
Severe
Proliferative
Proliferative
Average
Average
Normal

Normal
Mild
Moderate
Moderate
Severe
Severe
Proliferative
Proliferative
Average
Average
Mild

Accuracy
92.22
96.86

92.22
96.59
96.86
97.00
96.59
95.77
97.00
95.69
95.77
95.69
91.62
96.4991.62
96.8896.49
97.0896.88
95.7197.08
95.5695.71

95.56
93.64

93.64
97.73
95.91
95.91
96.82
96.82
95.9195.91
96.0096.00
97.73

Precision
Recall
89.58
95.29
Entire
Dataset
88.06
79.73
89.58
95.29
93.53
94.00
88.06
79.73
84.00
53.85
93.53
94.00
75.00
71.19
84.00
53.85
86.04
78.81
75.00
71.19
Training
86.04 Phase (70%)
78.81
89.01
94.92
Training
Phase (70%)
89.58
76.79
89.01
94.92
93.62
94.96
89.58
76.79
93.62
94.96
92.31
46.15
92.31
46.15
68.42
72.22
68.42
72.22
86.59
77.01
86.59
77.01
Testing Phase (30%)
Testing Phase (30%)
90.99
96.19
90.99
96.19
84.21
88.89
84.21
88.89
93.33
91.80
93.33
91.80
75.00
69.23
75.00
69.23
88.89
69.57
88.89
69.57
86.48
83.14
86.48
83.14

Specificity
89.25

F-Score
92.35

98.79

83.69

89.25
97.56
98.79
99.42
97.56
97.92
99.42
96.59
97.92
96.59

92.35
93.77
83.69
65.62
93.77
73.04
65.62
81.69
73.04
81.69

88.33

91.87

98.91
88.33

82.69
91.87

97.59
98.91
97.59
99.79
99.79
97.48
97.48
96.42
96.42

94.29
82.69
94.29
61.54
61.54
70.27
70.27
80.13
80.13

91.30

91.30
98.51
98.51
97.48
97.48
98.55
98.55
98.98
98.98
96.97
96.97

93.52

93.52
86.49
86.49
92.56
92.56
72.00
72.00
78.05
78.05
84.52
84.52

Figure
4. 4.Result
approachunder
underthe
theAPTOS
APTOS
2019
dataset.
Figure
Resultanalysis
analysisof
ofthe
the XAITO-DRGC
XAITO-DRGC approach
2019
dataset.

Appl.
FOR PEER REVIEW
Sci. 2022,
2022, 12,
12, x8749
Appl. Sci.

18
111111
ofofof1818

The training
trainingaccuracy
accuracy(TA)
(TA)and
andvalidation
validationaccuracy
accuracy(VA)
(VA)acquired
acquiredby
bythe
theXAITOXAITOtraining
accuracy
(TA)
and
validation
accuracy
(VA)
acquired
by
the
XAITOThe
DRGC method
methodon
onthe
theAPTOS
APTOS2019
2019dataset
datasetisis
isdemonstrated
demonstratedin
inFigure
Figure5.5.The
Theexperimental
experimental
method
on
the
APTOS
2019
dataset
demonstrated
in
Figure
The
experimental
DRGC
outcome denoted
has
reached
maximal
values
of TA
and
denoted that
thatthe
theXAITO-DRGC
XAITO-DRGCalgorithm
algorithm
has
reached
maximal
values
TA
outcome
the
XAITO-DRGC
algorithm
has
reached
maximal
values
ofofTA
VA. VA.
In particular,
the VA
greater
thanthan
TA. TA.
particular,
theisVA
VA
is greater
greater
than
TA.
and
In particular,
the
is

Figure
Figure 5.
5. TA
TA and
andVA
VA analysis
analysis of
of the
the XAITO-DRGC
XAITO-DRGC approach
approach
under
the
APTOS
2019
dataset.
Figure
5.
TA
and
VA
approachunder
underthe
theAPTOS
APTOS2019
2019dataset.
dataset.

The
Thetraining
trainingloss
loss(TL)
(TL)and
andvalidation
validationloss
loss(VL)
(VL)gained
gainedby
bythe
theXAITO-DRGC
XAITO-DRGCmethodmethodThe
training
loss
(TL)
and
validation
loss
(VL)
gained
by
the
XAITO-DRGC
methodology on
on ttthe
APTOS2019
2019dataset
datasetare
areestablished
establishedin
inFigure
Figure6.6.
6.The
Theexperimental
experimentaloutcome
outcome
ology
he
ology
on
he APTOS
APTOS
2019
dataset
are
established
in
Figure
The
experimental
outcome
impliedthat
thatthe
theXAITO-DRGC
XAITO-DRGCmethod
methodhas
hasaccomplished
accomplishedminimal
minimalvalues
valuesof
ofTL
TLand
andVL.
VL.
implied
implied
that
the
XAITO-DRGC
method
has
accomplished
minimal
values
of
TL
and
VL.
Explicitly,
VL
is
lesser
than
TL.
Explicitly,
the
VL
is
lesser
than
TL.
Explicitly, the VL is lesser than TL.

Figure
Figure 6.
6. TL
TLand
andVL
VLanalysis
analysisof
ofthe
theXAITO-DRGC
XAITO-DRGCapproach
approachunder
underthe
theAPTOS
APTOS2019
2019dataset.
dataset.
Figure 6. TL and VL analysis of the XAITO-DRGC approach under the APTOS 2019 dataset.

Appl. Sci. 2022, 12, 8749

12 of 18

Appl. Sci. 2022, 12, x FOR PEER REVIEW

12 of 18

To establish the enhanced performance of the XAITO-DRGC model, a comparison
study is made on the APTOS 2019 dataset in Table 3 and Figure 7 [25]. The results implied
To establish the enhanced performance of the XAITO-DRGC model, a comparison
that the CNN299 method has shown lower classification performance. At the same time,
study is made on the APTOS 2019 dataset in Table 3 and Figure 7 [25]. The results implied
the CNN512, CN299-dropout, EfficientNetB0, and EfficientNetB0-dropout models have
that the CNN299 method has shown lower classification performance. At the same time,
demonstrated moderately improved classifier results. Moreover, the CNN512-dropout
the CNN512, CN299-dropout, EfficientNetB0, and EfficientNetB0-dropout models have
model has reached reasonable performance with accuy of 88.60%, sensy of 81.56%, and
demonstrated moderately improved classifier results. Moreover, the CNN512-dropout
specy of 95.10%. However, the XAITO-DRGC model has outperformed other models with
model has reached reasonable performance with ğ‘ğ‘ğ‘ğ‘¢ of 88.60%, ğ‘ ğ‘’ğ‘›ğ‘  of 81.56%, and
a maximum accuy of 96.00%, sensy of 83.14%, and specy of 96.97%.
ğ‘ ğ‘ğ‘’ğ‘ of 95.10%. However, the XAITO-DRGC model has outperformed other models
with a maximum ğ‘ğ‘ğ‘ğ‘¢ of 96.00%, ğ‘ ğ‘’ğ‘›ğ‘  of 83.14%, and ğ‘ ğ‘ğ‘’ğ‘ of 96.97%.

Table 3. Comparative analysis of the XAITO-DRGC approach with recent methods on the APTOS
2019 dataset.
Table 3. Comparative analysis of the XAITO-DRGC approach with recent methods on the APTOS
2019 dataset.
Methods
Accuracy
Sensitivity
Specificity

Methods
XAITO-DRGC
XAITO-DRGC
CNN299
CNN299
CNN299-dropout
CNN299-dropout
CNN512
CNN512
CNN512-dropout
CNN512-dropout
EfficientNetB0
EfficientNetB0
EfficientNetB0-dropout
EfficientNetB0-dropout

Accuracy
96.00
80.0096.00
83.3080.00

83.30
85.80
88.60
88.60
82.3082.30
82.2082.20
85.80

Sensitivity
83.14
83.14
81.54
81.54
82.37
82.37
80.80
80.80
81.56
81.56
82.80
82.80
81.13
81.13

Specificity
96.97
96.97
81.51
81.51
84.81
84.81
95.30
95.30
95.10
95.10
88.07
88.07
83.75
83.75

Figure 7. Comparative analysis of the XAITO-DRGC approach under the APTOS 2019 dataset.
Figure 7. Comparative analysis of the XAITO-DRGC approach under the APTOS 2019 dataset.

Figure 8 signifies the confusion matrices given by the XAITO-DRGC method on the
Figure 8 signifies the confusion matrices given by the XAITO-DRGC method on the
DDR dataset. On the entire dataset, the XAITO-DRGC algorithm has identified 1225 samDDR dataset. On the entire dataset, the XAITO-DRGC algorithm has identified 1225 samples as normal, 105 samples as mild, 867 samples as moderate, 31 samples as severe, and
ples as normal, 105 samples as mild, 867 samples as moderate, 31 samples as severe, and
159 samples as proliferative. Furthermore, on 70% of TR data, the XAITO-DRGC

Appl. Sci. 2022, 12, 8749
Appl. Sci. 2022, 12, x FOR PEER REVIEW

13 of 18
13 of 18

159 samples as proliferative. Furthermore, on 70% of TR data, the XAITO-DRGC techtechnique
has identified
853 samples
as normal,
76 samples
as mild,
606 samples
as modnique
has identified
853 samples
as normal,
76 samples
as mild,
606 samples
as moderate,
erate,
22 samples
as severe,
and
112 samples
as proliferative.
Additionally,
onof
30%
TS
22
samples
as severe,
and 112
samples
as proliferative.
Additionally,
on 30%
TS of
data,
data,
the XAITO-DRGC
methodology
has identified
372 samples
as normal,
29 samples
the
XAITO-DRGC
methodology
has identified
372 samples
as normal,
29 samples
as mild,
as mild,
261 samples
as moderate,
samples
severe,
and 47 as
samples
as proliferative.
261
samples
as moderate,
9 samples9 as
severe,asand
47 samples
proliferative.

Figure 8.
8. Confusion
Confusionmatrices
matricesofofthe
theXAITO-DRGC
XAITO-DRGC
approach
under
DDR
dataset
(a) entire
daFigure
approach
under
thethe
DDR
dataset
(a) entire
dataset,
taset,
(b)
70%
of
TR
data,
and
(c)
30%
of
TS
data.
(b) 70% of TR data, and (c) 30% of TS data.

Table 44 and
and Figure
Figure 99 present
present an
an overall
overall classification
classification output
output of
of the
the XAITO-DRGC
XAITO-DRGC
Table
technique on the DDR
DDR dataset.
dataset. The experimental
experimental values notified that the
the XAITO-DRGC
XAITO-DRGC
method has shown enhanced results under
under distinct
distinct aspects.
aspects. For example, with the entire
dataset, the XAITO-DRGC
XAITO-DRGC method
methodhas
hasrendered
renderedan
anaverage
averageğ‘ğ‘ğ‘ğ‘¢
accuy of
of 98.15%,
98.15%, ğ‘ğ‘Ÿğ‘’ğ‘
precn of
92.13%, reca
86.26%,
spec
andand
Fscoreğ¹ of 88.78%.
At the
time,time,
with with
70%
86.26%,
ğ‘ ğ‘ğ‘’ğ‘
of 98.55%,
of 88.78%.
Atsame
the same
ğ‘Ÿğ‘’ğ‘ğ‘
y of 98.55%,
l ofof
of
TRofdata,
XAITO-DRGC
technique
has offered
an average
accuy ofğ‘ğ‘ğ‘ğ‘¢
98.11%,
of prec
98.11%,
70%
TR the
data,
the XAITO-DRGC
technique
has offered
an average
n of
93.89%,
reca
of
85.90%,
spec
of
98.45%,
and
F
of
89.31%.
Finally,
with
30%
of
TS
data,
ğ‘Ÿğ‘’ğ‘ğ‘ of 85.90%,
ğ‘ ğ‘ğ‘’ğ‘ of 98.45%,
and ğ¹
of 89.31%. Finally, with
ğ‘ğ‘Ÿğ‘’ğ‘ of 93.89%,
y
score
l

. Sci. 2022, Appl.
12, x FOR
PEER12,
REVIEW
Sci. 2022,
8749

14 of 18

14 of 18

the XAITO-DRGC
methodology
has rendered
an average
30% of TS data,
the XAITO-DRGC
methodology
has rendered
an accu
average
ğ‘ğ‘ğ‘ğ‘¢ prec
of n of 88.32%,
y of 98.24%,
87.30%,
specyofof87.30%,
98.77%,ğ‘ ğ‘ğ‘’ğ‘
and Fscore
of 87.54%.
88.32%,
ğ‘Ÿğ‘’ğ‘ğ‘
of 98.77%,
and ğ¹
of 87.54%.
98.24%, ğ‘ğ‘Ÿğ‘’ğ‘recaofl of
Table 4. Result
analysis
of theanalysis
XAITO-DRGC
approach withapproach
various measures
on the
DDR daTable
4. Result
of the XAITO-DRGC
with various
measures
on the DDR dataset.
taset.
Labels

Labels

Accuracy
Normal

Normal
97.12
Mild
Mild
98.56
Moderate
Moderate
97.48
Severe
Severe
99.24
Proliferative
Proliferative
98.32
Average
Average
98.15
Normal

Normal
96.86
Mild
Mild
98.57
Moderate
Moderate
97.37
Severe
Severe
99.32
Proliferative
Proliferative
98.40
Average
Average
98.11
Normal
Normal
97.74
Mild
Mild
98.54
Moderate Moderate
97.74
Severe99.07
Severe
Proliferative Proliferative
98.14
Average
Average
98.24

Accuracy

Precision

Sensitivity

Precision
Sensitivity
Entire DatasetSpecificity
Entire
Dataset
97.12
96.53
97.77
96.53
97.77
96.48
98.56
87.50
83.33
87.50
83.33
99.37
97.48
96.12
96.87
96.12
96.87
97.82
99.24
91.18
65.96
91.18
65.96
99.88
98.32
89.33
87.36
89.33
87.36
99.18
98.15
92.13
86.26
92.13
86.26
98.55
Training Phase (70%)
Training Phase (70%)
96.86
95.95
97.82
95.95
97.82
95.91
98.57
90.48
81.72
90.48
81.72
99.52
97.37
95.58
97.12
95.58
97.12
97.52
99.32
95.65
66.67
95.65
66.67
99.94
98.40
91.80
86.15
91.80
86.15
99.38
98.11
93.89
85.90
93.89
85.90
98.45
Testing Phase (30%)
Testing Phase (30%)
97.74
97.89
97.64
97.89
97.64
97.84
98.54
80.56
87.88
80.56
87.88
99.03
97.74
97.39
96.3198.54
97.39
96.31
99.07
81.82
64.2999.73
81.82
64.29
98.14
83.93
90.3898.71
83.93
90.38
98.24
88.32
87.30
88.32
87.30
98.77

Specificity

F-Score

F-Score
96.48

97.15
99.37
85.37
97.82
96.49
99.88
76.54
99.18
88.33
98.55
88.78
95.91

96.88
99.52
85.88
97.52
96.34
99.94
78.57
99.38
88.89
98.45
89.31
97.84

97.77
99.03
84.06
98.54
96.85
99.73
72.00
98.71
87.04
98.77
87.54

Figure
9. Result
of the XAITO-DRGC
approach
the DDR dataset.
Figure 9. Result
analysis
of theanalysis
XAITO-DRGC
approach under
the DDRunder
dataset.

97.15
85.37
96.49
76.54
88.33
88.78

96.88
85.88
96.34
78.57
88.89
89.31

97.77
84.06
96.85
72.00
87.04
87.54

Appl. Sci. 2022, 12, x FOR PEER REVIEW

Appl. Sci. 2022, 12, 8749

15 of 18

15 of 18

The TA and VA acquired by the XAITO-DRGC technique on the DDR dataset are
Appl. Sci. 2022, 12, x FOR PEER REVIEW
15 ofhas
18
shown in Figure 10. The experimental outcome denoted the XAITO-DRGC algorithm
reached maximal values of TA and VA. In particular, the VA is greater than TA.
The
VAattained
acquired
XAITO-DRGC
technique
thedataset
DDR dataset
are
TheTA
TL and VL
byby
thethe
XAITO-DRGC
method
on the on
DDR
are estabshown
in
The
experimental
outcome
denoted
the the
XAITO-DRGC
has
lished
in Figure
Figure
11.
experimental
represented
XAITO-DRGC
approach
The
TA
and10.
VA
acquired
by the outcome
XAITO-DRGC
technique
on the DDRalgorithm
dataset
are
reached
maximal
values
of TA
andof
VA.
In
particular,
thethe
VAXAITO-DRGC
is
greater
thanalgorithm
TA.
has accomplished
minimal
values
TL
and
VL.denoted
Specifically,
the
VL is lesser
than TL.has
shown
in
Figure 10.
The experimental
outcome
reached maximal values of TA and VA. In particular, the VA is greater than TA.
The TL and VL attained by the XAITO-DRGC method on the DDR dataset are established in Figure 11. The experimental outcome represented the XAITO-DRGC approach
has accomplished minimal values of TL and VL. Specifically, the VL is lesser than TL.

Figure10.
10.TA
TAand
andVA
VAanalysis
analysisof
ofthe
the XAITO-DRGC
XAITO-DRGC approach
approach under
Figure
under the
the DDR
DDRdataset.
dataset.

The TL and VL attained by the XAITO-DRGC method on the DDR dataset are established in Figure 11. The experimental outcome represented the XAITO-DRGC approach
has
accomplished
minimal
of TL and VL.
Specifically,
lesser than TL.
Figure
10. TA and VA
analysisvalues
of the XAITO-DRGC
approach
underthe
the VL
DDRisdataset.

Figure 11. TL and VL analysis of the XAITO-DRGC approach under the DDR dataset.

Figure11.
11.TL
TL and
and VL
VL analysis
analysis of
Figure
of the
the XAITO-DRGC
XAITO-DRGCapproach
approachunder
underthe
theDDR
DDRdataset.
dataset.

Appl. Sci. 2022, 12, 8749

16 of 18

Appl. Sci. 2022, 12, x FOR PEER REVIEW

16 of 18

To establish the enhanced performance of the XAITO-DRGC method, a comparative
studyToisestablish
made onthe
theenhanced
DDR dataset
in Table 5ofand
12. The results
represented
that
performance
theFigure
XAITO-DRGC
method,
a comparative
the CNN299
method
lower
performance.
the CNN512,
study
is made
on thedisplayed
DDR dataset
in classification
Table 5 and Figure
12. TheMeanwhile,
results represented
that
CN299-dropout,
EfficientNetB0,
and
EfficientNetB0-dropout
models
have
demonstrated
the CNN299 method displayed lower classification performance. Meanwhile, the
moderatelyCN299-dropout,
enhanced classifier
results. Along
withEfficientNetB0-dropout
that, the CNN512-dropout
approach
CNN512,
EfficientNetB0,
and
models
have
has
attained
reasonable
performance
with
accu
of
84.10%,
sens
of
85.11%,
and
specy of
y
demonstrated moderately enhanced classifier results.
Along withy that, the CNN512-drop84.80%,
however,
XAITO-DRGC
technique
has outperformed
other
models
withofa
out
approach
has the
attained
reasonable
performance
with ğ‘ğ‘ğ‘ğ‘¢ of
84.10%,
ğ‘ ğ‘’ğ‘›ğ‘ 
maximum
accu
senshowever,
specy of 98.77%.
y of 98.24%,
y of 87.30%,
of 84.80%,
theand
XAITO-DRGC
technique has outperformed
85.11%,
and
ğ‘ ğ‘ğ‘’ğ‘

other models with a maximum ğ‘ğ‘ğ‘ğ‘¢

of 98.24%, ğ‘ ğ‘’ğ‘›ğ‘  of 87.30%, and ğ‘ ğ‘ğ‘’ğ‘ of 98.77%.

Table 5. Comparative analysis of the XAITO-DRGC approach with recent methods on the DDR
dataset.
Table
5. Comparative analysis of the XAITO-DRGC approach with recent methods on the DDR

dataset.

Methods

Methods
XAITO-DRGC
XAITO-DRGC
CNN299
CNN299
CNN299-dropout
CNN299-dropout
CNN512
CNN512
CNN512-dropout
CNN512-dropout
EfficientNetB0
EfficientNetB0
EfficientNetB0-dropout
EfficientNetB0-dropout

Accuracy
98.24Accuracy
82.10
83.20
83.40
84.10
82.30
82.20

98.24
82.10
83.20
83.40
84.10
82.30
82.20

Sensitivity

Sensitivity
87.30
87.30
82.96
82.96
82.62
82.62
83.83
83.83
85.11
85.11
82.00
82.00
81.49
81.49

Specificity

Specificity
98.77
98.77
82.39
82.39
82.45
82.45
83.67
83.67
84.80
84.80
81.62
81.62
81.34
81.34

Figure 12. Comparative analysis of the XAITO-DRGC approach under the DDR dataset.
Figure 12. Comparative analysis of the XAITO-DRGC approach under the DDR dataset.

From the above-mentioned tables and graphs, it is evident that the XAITO-DRGC
From
above-mentioned
tables andover
graphs,
is evident that the XAITO-DRGC
method
hasthe
shown
enhanced performance
otheritmodels.
method has shown enhanced performance over other models.

Appl. Sci. 2022, 12, 8749

17 of 18

5. Conclusions
In this article, a new XAITO-DRGC technique was projected for the detection and
classification of DR. The presented XAITO-DRGC model utilizes OphthoAI IoMT headsets
to enable remote monitoring of DR disease. Initially, the XAITO-DRGC model applies MF
and contrast enhancement as a pre-processing step. In addition, the XAITO-DRGC model
applies U-Net-based image segmentation and SqueezeNet-based feature extractor. Finally,
AOA with BGRCU is exploited for DR detection and classification where the AOA assist in
optimal hyperparameter tuning of the BGRCU model. The experimental validation of the
XAITO-DRGC technique can be tested using a benchmark dataset and the outcomes were
assessed under distinct prospects. Extensive comparison studies stated the enhancements
of the XAITO-DRGC model over recent approaches with maximum accuracy of 98.24%
whereas the existing CNN512-dropout model has attained reduced accuracy of 84.10%
on the DDR dataset. In the future, the presented method is extended to the design of
fusion-based DL models.
Author Contributions: Conceptualization, M.O.; Data curation, N.N.; Formal analysis, N.N.; Funding acquisition, M.A.D.; Investigation, M.K.N.; Methodology, M.O.; Project administration, M.K.N.
and M.A.D.; Resources, H.M.; Software, H.M. and M.R.; Supervision, M.R. and A.S.Z.; Validation,
A.S.Z. and A.M.; Visualization, A.M.; Writingâ€”original draft, M.O.; Writingâ€”review & editing,
M.A.D. All authors have read and agreed to the published version of the manuscript.
Funding: The authors extend their appreciation to the Deanship of Scientific Research at King
Khalid University for funding this work through the Large Groups Project under grant number
(71/43). Princess Nourah bint Abdulrahman University Researchers Supporting Project number
(PNURSP2022R203), Princess Nourah bint Abdulrahman University, Riyadh, Saudi Arabia. The authors would like to thank the Deanship of Scientific Research at Umm Al-Qura University for
supporting this work by Grant Code: 22UQU4310373DSR35.
Institutional Review Board Statement: Not applicable.
Informed Consent Statement: Not applicable.
Data Availability Statement: Data sharing is not applicable to this article as no datasets were
generated during the current study.
Conflicts of Interest: The authors declare that they have no conflict of interest. The manuscript was
written with the contributions of all authors. All authors have given approval for the final version of
the manuscript.

References
1.
2.
3.
4.
5.

6.

7.
8.

Horton, M.B.; Brady, C.J.; Cavallerano, J.; Abramoff, M.; Barker, G.; Chiang, M.F.; Crockett, C.H.; Garg, S.; Karth, P.; Liu, Y.; et al.
Practice Guidelines for Ocular Telehealth-Diabetic Retinopathy. Telemed. e-Health 2020, 26, 495â€“543. [CrossRef] [PubMed]
Pieczynski, J.; Kuklo, P.; Grzybowski, A. The Role of Telemedicine, In-Home Testing and Artificial Intelligence to Alleviate an
Increasingly Burdened Healthcare System: Diabetic Retinopathy. Ophthalmol. Ther. 2021, 10, 445â€“464. [CrossRef]
Ting, D.S.J.; Ang, M.; Mehta, J.S.; Ting, D.S.W. Artificial intelligence-assisted telemedicine platform for cataract screening and
management: A potential model of care for global eye health. Br. J. Ophthalmol. 2019, 103, 1537â€“1538. [CrossRef]
Agrawal, S.; Strzelec, B.; PorË›eba, R.; Agrawal, A.; Mazur, G. Clinical Characteristics, Preventive Care and Attitude to Telemedicine
among Patients with Diabetic Retinopathy: A Cross-Sectional Study. J. Clin. Med. 2021, 10, 249. [CrossRef]
Galiero, R.; Pafundi, P.C.; Nevola, R.; Rinaldi, L.; Acierno, C.; Caturano, A.; Salvatore, T.; Adinolfi, L.E.; Costagliola, C.; Sasso, F.C.
The Importance of Telemedicine during COVID-19 Pandemic: A Focus on Diabetic Retinopathy. J. Diabetes Res. 2020, 2020, 1â€“8.
[CrossRef] [PubMed]
Mansberger, S.L.; Sheppler, C.; Barker, G.; Gardiner, S.K.; Demirel, S.; Wooten, K.; Becker, T.M. Long-term comparative
effectiveness of telemedicine in providing diabetic retinopathy screening examinations: A randomized clinical trial. JAMA
Ophthalmol. 2015, 133, 518â€“525. [CrossRef] [PubMed]
Grauslund, J. Diabetic retinopathy screening in the emerging era of artificial intelligence. Diabetologia 2022, 65, 1415â€“1423.
[CrossRef] [PubMed]
Nakayama, L.F.; Ribeiro, L.Z.; GonÃ§alves, M.B.; Ferraz, D.A.; dos Santos, H.N.V.; Malerbi, F.K.; Morales, P.H.; Maia, M.; Regatieri,
C.V.S.; Mattos, R.B. Diabetic retinopathy classification for supervised machine learning algorithms. Int. J. Retin. Vitr. 2022, 8, 1â€“5.
[CrossRef] [PubMed]

Appl. Sci. 2022, 12, 8749

9.

10.

11.

12.

13.
14.

15.
16.
17.

18.
19.
20.
21.
22.
23.
24.
25.

18 of 18

Salman, O.H.; Taha, Z.; Alsabah, M.Q.; Hussein, Y.S.; Mohammed, A.S.; Aal-Nouman, M. A review on utilizing machine
learning technology in the fields of electronic emergency triage and patient priority systems in telemedicine: Coherent taxonomy,
motivations, open research challenges and recommendations for intelligent future work. Comput. Methods Programs Biomed. 2021,
209, 106357. [CrossRef] [PubMed]
Fonda, S.J.; Bursell, S.-E.; Lewis, D.G.; Clary, D.; Shahon, D.; Horton, M.B. The Indian Health Service Primary Care-Based
Teleophthalmology Program for Diabetic Eye Disease Surveillance and Management. Telemed. e-Health 2020, 26, 1466â€“1474.
[CrossRef] [PubMed]
Wijesinghe, I.; Gamage, C.; Perera, I.; Chitraranjan, C. A Smart Telemedicine System with Deep Learning to Manage Diabetic
Retinopathy and Foot Ulcers. In Proceedings of the IEEE 2019 Moratuwa Engineering Research Conference (MERCon), Moratuwa,
Sri Lanka, 3â€“5 July 2019; pp. 686â€“691.
Reddy, G.T.; Bhattacharya, S.; Ramakrishnan, S.S.; Chowdhary, C.L.; Hakak, S.; Kaluri, R.; Reddy, M.P.K. An ensemble based
machine learning model for diabetic retinopathy classification. In Proceedings of the IEEE 2020 International Conference on
Emerging Trends in Information Technology and Engineering (ic-ETITE), Vellore, India, 24â€“25 February 2020; pp. 1â€“6.
Hacisoftaoglu, R.E.; Karakaya, M.; Sallam, A.B. Deep learning frameworks for diabetic retinopathy detection with smartphonebased retinal imaging systems. Pattern Recognit. Lett. 2020, 135, 409â€“417. [CrossRef] [PubMed]
Choudhury, A.R.; Bhattacharya, D.; Debnath, A.; Biswas, A. An Integrated Image Processing and Deep Learning Approach
for Diabetic Retinopathy Classification. In International Conference on Computational Intelligence, Security and Internet of Things;
Springer: Singapore, 2020; pp. 3â€“15.
Papon, M.; Islam, T. Design and Development of a Deep Learning Based Application for Detecting Diabetic Retinopathy. 2019.
Available online: http://lib.buet.ac.bd:8080/xmlui/handle/123456789/5340 (accessed on 3 June 2022).
Fayemiwo, M.A.; Akinboro, S.A.; Adepegba, O.A. Identification and Classification of Diabetic Retinopathy Using Machine
Learning. Adeleke Univ. J. Eng. Technol. 2018, 1, 245â€“259.
Kumar, S.; Yadav, J.S.; Kurmi, Y.; Baronia, A. An efficient image denoising approach to remove random valued impulse noise
by truncating data inside sliding window. In Proceedings of the IEEE 2nd International Conference on Data, Engineering and
Applications (IDEA), Bhopal, India, 28â€“29 February 2020; pp. 1â€“7.
Saood, A.; Hatem, I. COVID-19 lung CT image segmentation using deep learning methods: U-Net versus SegNet. BMC Med.
Imaging 2021, 21, 1â€“10. [CrossRef] [PubMed]
Gysel, P.; Pimentel, J.; Motamedi, M.; Ghiasi, S. Ristretto: A Framework for Empirical Study of Resource-Efficient Inference in
Convolutional Neural Networks. IEEE Trans. Neural Networks Learn. Syst. 2018, 29, 5784â€“5789. [CrossRef] [PubMed]
Nussbaum-Thom, M.; Cui, J.; Ramabhadran, B.; Goel, V. Acoustic Modeling Using Bidirectional Gated Recurrent Convolutional
Units. In Proceedings of the Interspeech 2016, San Francisco, CA, USA, 8â€“12 September 2016; pp. 390â€“394.
Hashim, F.A.; Hussain, K.; Houssein, E.H.; Mabrouk, M.S.; Al-Atabany, W. Archimedes optimization algorithm: A new
metaheuristic algorithm for solving optimization problems. Appl. Intell. 2020, 1â€“21. [CrossRef]
Neggaz, I.; Fizazi, H. An Intelligent handcrafted feature selection using Archimedes optimization algorithm for facial analysis.
Soft Comput. 2022, 1â€“30. [CrossRef] [PubMed]
Li, T.; Gao, Y.; Wang, K.; Guo, S.; Liu, H.; Kang, H. Diagnostic assessment of deep learning algorithms for diabetic retinopathy
screening. Inf. Sci. 2019, 501, 511â€“522. [CrossRef]
APTOS 2019 Blindness Detection. Available online: https://www.kaggle.com/c/aptos2019-blindness-detection/overview/
evaluation (accessed on 13 May 2022).
Alyoubi, W.; Abulkhair, M.; Shalash, W. Diabetic Retinopathy Fundus Image Classification and Lesions Localization System
Using Deep Learning. Sensors 2021, 21, 3704. [CrossRef] [PubMed]

