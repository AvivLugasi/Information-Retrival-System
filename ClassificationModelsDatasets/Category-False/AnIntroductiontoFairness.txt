Chapter 20: An Introduction to Fairness, Absence of Bias, and Equity in Learning Analytics 
Suraj Uttamchandani,1Joshua Quick2 
1 Center for Research on Learning and Technology, Indiana University, Bloomington, USA 2 eLearning Research & Practice Lab, Indiana University, Bloomington, USA 
DOI: 10.18608/hla22.020 
ABSTRACT 
In this chapter, we examine the ways educational justice has been and may be taken up in learning analytics research. To do so, we first outline how we see equity as playing a necessary role in the future development of the learning analytics community. Next, we review how equity has been explored in this area heretofore, focusing on notions of algorithmic fairness and absence of bias. Then, we turn to newer political approaches to the study of learning that are emerging in the learning sciences. We summarize trends in this research’s conceptualizations of equity and the political dimensions of learning. Finally, we connect these related ways of thinking about social justice with respect to learning analytics, and examine the tensions and possibilities at their intersection. We close with some recommendations for the learning analytics field to ensure that it contributes to positive educational change moving into the future. 
Keywords: Equity, educational justice, fairness, bias 
Broadly speaking, an equity orientation to education rec ognizes that people in general and children in particular have a fundamental right to education [43, 42]. It ac knowledges that there are massive disparities in people’s experiences of educational environments (including, but not limited to, in educational outcomes). These disparities are often related to learners’ race, gender, sexual orienta tion, ability status, and/or economic status (in the United States, see for example [13, 34]). Ameliorating these in equities—and offering alternatives that empower learners and challenge oppressive social structures—is a primary goal of equity-forward educational research. 
When it comes to learning analytics, we focus our atten tion on equity with respect to researching, designing, and enacting learning environments. Elsewhere in this vol ume, authors discuss learning analytics as they relate to ethics (Prinsloo et al., this volume), scale (Reich et al., this volume), and policy (Scheffel et al., this volume). Each of these is an important part of designing for equity. There fore, we embrace a relatively narrow scope in discussing equity, which for the purposes of this chapter focuses on when and how learning analytics can be culturally, socially, and politically responsive to a diverse array of students. Importantly, we address this chapter to read ers with a desire to improve education, recognizing that equity is a central concern in such a goal. 
Undoubtedly, algorithmic approaches, complex computa tions, and machine learning are not a priori helpful, just, 
ethical or likely to increase quality of life for many. They are not even neutral in this regard [45]. Rather, countless examples detail how an uncritical perspective on these an alytics and their uses has had just the opposite effect, lead ing to what Eubanks [21] refers to as automating inequality and what Noble [44] has called technological redlining. In deed, without a critical perspective, learning analytics are not only unlikely to deliver on promises of bringing about positive educational change; worse, they are likely to reinscribe and make more efficient existing systemic discriminatory practices. 
We do not think it is a foregone conclusion that learning analytics will play such a role moving into the future. On the contrary, we see great potential in the advanced ap proaches being taken by this community for improving students’ educational experiences. However, we under stand that potential to be most probably realized if the learning analytics community is proactive in taking on critical, political, and nuanced approaches to equity. 
In this chapter, we begin by reviewing how the learning analytics community, to date, has approached issues of equity. In general, this has been through the notions of algorithmic fairness and absence of bias. Next, we turn to how scholars in the learning sciences have recently be gun to theorize the political dimensions of learning to advance a more justice-centered perspective on learning. We recognize that the learning sciences is only one of a wide variety of fields that contribute to learning analytics 
CHAPTER 20: FAIRNESS, BIAS & EQUITY | PG 205
insights. Furthermore, relative to fields like ethnic studies and qualitative methodology, the learning sciences is at the outset of its thinking about equity, and its conceptions of equity are informed by these fields. Nonetheless, it is in this space that some of the strongest thinking connecting justice projects to learning processes is taking place. Fur thermore, many have argued that the learning analytics and learning sciences communities are well positioned to learn from and contribute to one another [56, 62]. We conclude by exploring tensions and possibilities at the in tersection of these communities’ ways of taking up equity, drawing from critical technology studies to close with some recommendations. 
FAIRNESS AND ABSENCE OF BIAS: CURRENT VIEWS FROM LEARNING ANALYTICS 
Issues of equity in learning analytics are an extension of observed problems in algorithm-informed decision mak ing. As Safiya Noble indicates in Algorithms of Oppression [44], the development of an algorithmic or analytic pro cess can easily incorporate the biases of those who de sign it, and employing such biased algorithms enforces unjust perceptions, policies, and practices of oppressing marginalized communities. For example, word associa tion algorithms, such as GloVe (Global Vectors for Word Representations) can embed into their associations prob lematic racial and gendered stereotypes, in turn propagat ing problematic decision making in the tool’s application for hiring or admission processes [9]. Such issues entail a precarious dilemma within learning analytics since deci sions made from learning analytic processes can directly impact learner experiences and participation in terms of what is represented and enabled through these systems. Given the principle importance of education as a means to participate in larger social systems, it is not surprising that the scholarship within learning analytics has begun to discuss what constitutes equitable practices of algorithm informed decision making for teaching and learning. 
Indeed, such concerns have been a pertinent debate in learning analytics at the end of the decade. Niel Selwyn’s provocative considerations in his LAK’18 keynote chal lenged scholars to consider the ways in which existing learning analytics practices can hinder access and deci sion making (see [60]). Direct replies to Selwyn’s concerns illustrate the constraints of analytics for making equitable and fair decisions for processes of teaching and learning (see [7, 20, 22, 51, 57]). In order to address these concerns, however, a larger perspective on the state of the field in terms of equitable or fair practices is necessary. 
Similar to broader concerns about the application of pre dictive algorithms (see [54]), the dangers of classification or predictive algorithms to determine who gets support, resources, and opportunities to participate in educational systems have long been a concern [52, 55]. Papers from the inaugural FairLAK workshop at LAK’19 exhibited re sponses to these concerns primarily through the lens of algorithmic fairness. We define algorithmic fairness as a 
PG 206 | HANDBOOK OF LEARNING ANALYTICS
property of a computational process wherein equivalent outcomes exist between a baseline and target group (e.g., 18-24 years old vs. 25-34 years old), though we recognize that the criteria and metric by which this is determined is an open discussion and multiple definitions have been proposed (see [24]). For example, Gardner et al. [25] used slicing analysis to compare disproportionate results in models. They showed that these comparisons can pro vide insight into model performance across populations and therefore potentially lead to more accurate predictive tools. Similarly, Doroudi and Brunskill [16] examined the fairness of knowledge tracing algorithms in terms of the susceptibility of these processes to inappropriately aggre gate input training data or make incorrect assumptions about students’ learning. They found that simulations of learners with different characteristics (e.g., “slow” vs. “fast” learners) revealed disproportionate outcomes for these learners in Bayesian knowledge tracing algorithms. These two approaches provide examples in using fairness as an evaluative component in the development of learn ing analytic models. 
Fairness (and, by extension, absence of bias) entail exam ining issues of inappropriate discriminations made by an algorithm or its use. Both of the previously discussed in stances sought quantitative measures of fairness in terms of the outcome of a model as a test or classification of a learner or group of learners. Fairness and absence of bias in learning analytic algorithms are therefore fundamen tally intertwined in whether an algorithmic process pro duces proportionally equal outcomes across demographic dimensions.1 These instances present an additional chal lenge, however, in whether “bias” is best understood as a property of the algorithmic process or a property of the decisions made from the use of these tools. This wider set of issues is one of the interaction of social and technical systems as producing biased or unfair practices. In our view, bias in learning analytics results from the intersec tion of what is represented within data and how these representations are employed in practice. Meaney and Fikes [37], for example, illustrate this nexus in their artic ulation of building systems based off of a group of early completers of tasks to detect issues across a course popu lation, and the consequent challenges other stakeholders faced in embedding outputs from this system in their prac tice. Specifically, the use of early completers of a task to construct a model ignores potential relevant differences in their participation compared to other learners, especially experiential and culturally-relevant differences that may not be represented in the task or the data produced from it. This allows for further embeddings of practices that may not support all learners, since the application of results is based on students who least need assistance and thus ignores those who may benefit most from more attention. The use of an analytic, then, is fundamentally situated and bound in the social functions it is intended to serve. Such uses are present in the use of machine learning tools in any social, and therefore value-laden, context (see [59]), 
1Alongside “fairness,” we tend to use the term “absence of bias” (rather than simply “bias”) to indicate that fairness and bias’s absence are both desired properties. 
of which education certainly qualifies. 
Paths to mitigate these sources of inequitable decision making are an emerging area of research in learning an alytics. Jones and McKay [30], for example, emphasized the need to involve practitioners in learning analytics and educational data science communities more directly in the design of analytic systems through reflection on ethical issues within the design of the tool before they manifest. This approach reflects broader efforts detailed at the in tersection of learning analytics and human computer in teraction design processes (i.e., human-centered learning analytics; see [7]) and focusing on the different valuations (social, cultural, and political) embedded within a com munity and its tools (see [10] for a review and application of value-centered design in learning analytics). 
It has further proven useful to consider learning analytics from a more critical, power-centric perspective. Drawing from the sociologically-informed discussions of critical data studies (see [3]) as well as emerging critical studies in the information sciences (such as the newly-formed International Journal of Information, Diversity, & Inclusion), this family of approaches attempts to consider learning analytics and the decisions made from them in terms of power and politics. Perrotta and Williamson [48], for example, articulated the role of valuations and decision making in the construction and execution of a clustering algorithm, thereby revealing hidden social and political assumptions in its implementation. Namely, the output from clustering algorithms applied to educational data describes a complex network of situated social, technical, and political choices, and this contextual attunement may be lost when algorithm results are implied to describe instrumental, transferable relations that can be unprob lematically transferred across learning contexts. Prinsloo [50] expands these discussions in considering data and the analytics thereof as constructed actors within the larger so cial, political, cultural, and technical systems and therefore entailing a set of social values and designs. The broader aims of this more critical approach, then, are to articulate the functions of use of analytics for teaching and learning in terms of how such metrics impact and are impacted by practices in a larger array of social, cultural, and political values. Naturally, this strand has much to offer in terms of what constitutes equitable processes and practices with learning analytics in larger social and political contexts, but has yet to fully be taken up in the development of analytics to assess the fairness of algorithms (as discussed in [25]). 
Fairness, absence of bias, and ultimately equitable analytic-based decision making in learning and educa tion represent an emergent, multifaceted challenge that substantively shifts in meaning and value depending on the affordances and constraints of the social and technical systems in which these tools are developed and deployed. Fundamentally, the determination of whether a learning analytic process is fair or free from bias must connect to the circumstances of the data quality available within an educational context and the literacy of those in a position to make decisions from such tools. Learning analytics 
as a path to promoting more agentic learning and thus disrupting existing barriers in participation in education must contend with these issues or risk producing no dis ruption at best or inimical changes at worst [63]. As such, the development of fair and equitable learning analytic practices represent fundamental questions for: (1) the use of algorithms that have been shown to not inappropriately discriminate across populations; (2) the integration and use of data systems that do not exclude or misrepresent groups in education, and; (3) the facilitation of literacy and development of learning analytic tools in and across contexts as a design process in and of itself. In this re gard, the extension of learning analytics into the related design intensive research of the learning sciences towards equitable learning environments is needed. 
POLITICAL APPROACHES AND EQUITY: NEW PERSPECTIVES FROM THE LEARNING SCIENCES 
In recent years, the learning sciences has also increased its attention to equity (e.g., [18, 49, 33]). While we recognize that the learning sciences is but one of many fields that inform learning analytics, we see immense opportunity for connection between these fields [56, 62, 70]. Given the particularly rich conversations in the learning sciences around issues of culture and equity as they relate to learn ing processes, in this section we turn to how notions of equity have been taken up in the learning sciences com munity. Note that while we ascribe these views to the learning sciences, the scholarship discussed next is best understood as working across a number of perspectives, including critical social theory, curriculum studies, and cultural psychology. 
To begin, it is necessary to acknowledge that disparities exist in people’s experiences of educational environments, participation practices, and learning outcomes (conceptu alized broadly). While oftentimes these disparities exist along racial, gendered, classed, or other visible lines, ac knowledging disparities in education does not imply that minoritized students’ backgrounds are deficits that need to be overcome for learning to take place. However, such a deficit perspective has been a dominant perspective in ed ucational research historically and persists still today [46]. Sociocultural learning theorists position culture as central in the study of learning [12, 27]. From an asset-based per spective of learners, students’ cultural backgrounds are often rich, and in an equitable learning space, people’s cultural backgrounds offer funds of knowledge that can productively contribute to learning [26, 38]. Culturally responsive pedagogy [32] and culturally-sustaining ped agogy [46] emerged as researchers and educators saw a need to position minoritized students’ backgrounds in this resource-based way. This need was driven by a sense that such pedagogies would improve educational out comes, but also that they offered students—particularly minoritized students—a more just and dignifying edu cational experience. Importantly, these critical cultural perspectives recognize that identity groups are not mono 
CHAPTER 20: FAIRNESS, BIAS & EQUITY | PG 207
lithic. In fact, they understand race (and many other social categorizations) to be a social construction rather than a biological reality [39]. Rather than treating culture as a static demographic variable, therefore, it is more appropri ate to focus on students’ prior cultural repertoires of practice to understand and design at the intersection of culture and learning [27]. 
From this perspective, there has been deep attention to unpacking culture as it relates to identity (e.g., [40, 28]). This necessitates investigating how culture relates to race, gender, sexuality, and other identity categories, and to power, privilege, and oppression as it surrounds these cat egories [41, 36, 18]. While from a sociocultural perspective learning is often about taking on new identities, identity is a joint accomplishment between learners and learning en vironments [28]. Students contend with racial and cultural storylines about who they can and cannot be [61]. In other words, identity and learning constrain together. This has led some scholars to center equitable disciplinary identi fication, focusing not only on how individuals navigate (usually STEM) disciplines, but also how such disciplines and communities function to become hostile to particular learners (e.g., [4, 35]). 
In conversation with these trends, some learning scientists have argued that all learning has a political dimension which requires consideration by learning researchers [5, 6, 33]. Foregrounding this political dimension necessi tates asking questions like “for whom,” “with whom,” and “to what ends” do people learn [49]? To really think through these questions, it is necessary to acknowledge that racism, heterosexism, sexism, genderism, ablism, settler-colonialism, and other systematic forms of discrim ination not only exist, but that these systemic discrimi nations are highly consequential for learners’ educative experiences and their lives [18]. Indeed, these historical in equities have compounded in a way that Ladson-Billings [31] argues creates an educational debt that is owed to mi noritized—and specifically in the United States, Black and Indigenous—people. Equity-focused learning scientists have also highlighted that heterogeneity in people and ideas is fundamental to learning [58] and productively expands the long-term projects of research disciplines like science [38]. Importantly, centering the political reminds us that the societal purposes of education and learning cannot be disregarded in research and design. Some argue that learning and education are most powerful when they center on the critical analysis and positive transformation of social circumstances [14, 23, 68]. Indeed, this learning must center the fundamental dignity of humans [17, 19] and more-than-humans [2, 67]. 
Together, these sociocultural and sociopolitical attune ments in learning theory and design research build on the sociocultural shift of focus from individual learning expe riences (such as how a person’s race affects their learning) to the design of learning environments (such as how an environment might enact, reify, or combat racism). They offer the potential to make or keep research relevant to everyday educational practice and to life improvement. They also advance learning theory by building our un 
PG 208 | HANDBOOK OF LEARNING ANALYTICS
derstanding of factors that affect where, when, and how people learn that have historically been understudied in the learning sciences, learning analytics, and educational psychology communities. Uttamchandani [64] summa rized these trends as comprising four equity pathways: (1) Consider the goals of an equity-oriented framework for learning; (2) Theoretically draw on existing critical social theory; (3) Methodologically, focus on collabora tive change-making, and; (4) Support heterogeneity in knowing and doing (i.e., in design). In these ways, we see equity and learning as having productive orientations to the historical, cultural, and political that can be more explicitly brought to bear in learning analytics research. Clearly, culture cannot be reduced to one (or, arguably, even many) algorithmic variable(s) in studying its rele vance for learners. However, there is still great promise for how equity, politics, culture, and cultural responsiveness can be meaningfully taken up at the intersection of these perspectives and existing learning analytics traditions. 
CONNECTING THE DOTS: FUTURE DIRECTIONS FOR EQUITABLE 
LEARNING ANALYTICS 
Looking across fairness and absence of bias (predomi nant views in learning analytics) and educational equity and justice (emerging views in the learning sciences), we conclude by exploring how the learning analytics com munity might take up these views to avoid furthering social inequality and instead offer powerful and scalable new ways to contribute to educational justice. We assert that it is impossible to discuss fairness, absence of bias, or equity in any meaningful way without discussing that which makes things unfair, biased, or inequitable: sys temic racism, heterosexism, sexism, genderism, ableism, nationalism, classism, religious discrimination, settler colonialism, and other dehumanizations that have been built into our day-to-day lives through legislation, poli tics, and broadly accepted but problematic social norms. Insofar as learning analytics work offers new ways to con ceptualize systems of learning, it must be cautious that these new learning systems do not absorb these surround ing oppressions, but rather actively combat them. At first glance, it may appear that fairness and absence of bias in learning analytics is quite unlike politicized approaches to the learning sciences. However, we argue that there is immense potential at the intersection of these two com munities. Given its scope and potential to scale, learning analytics can positively contribute to brighter social fu tures. For example, equity analytics [53] can be used to better understand students’ participation and thus lead to the identification of structures that produce inequitable experiences and outcomes—and new designs to combat such structures. To conclude this chapter, we offer some considerations we think are worth exploring at this inter section. 
Firstly, we argue that algorithmic fairness and absence of bias are an incomplete subset of equity orientations to learning analytics. While we agree that, at minimum, 
algorithms should be fair and unbiased, we also point to the fact that the “equity computation” being done in learning analytics must be sociohistorically situated. In other words, one cannot compute their way to a more eq uitable society, and it is incumbent on learning analytics researchers to conceptualize the fairness of their designs in terms of their ramifications for larger oppressive or emancipatory systems. This entails a highly critical per spective on “harmful data regimes” [11] and technology’s promises to revolutionize education [69], especially when these promises are made in the absence of serious con siderations of social justice (see Cifor et al.’s “Feminist Data Manifest-no” for more on what is entailed in ethical relationships with information and data [11]). 
Secondly, equitable learning analytics require detailed attention to the circumstances in which a tool has been developed and is deployed. In this regard, there exist sev eral relevant traditions such as human-centered design and participatory design, in which a diverse array of per spectives from those who may ultimately use a tool are foregrounded in the design of that tool and its contexts of use (see [15] for a helpful discussion of these and related terms). As Buckingham Shum et al. [7] indicated, more participatory strategies in the design of learning analytics can lead to greater insight in representing and interpret ing learning through learning analytics. Such design pro cesses also bring attention to the perspectives of different stakeholders and their circumstances. We contend these perspectives will also provide insight in fairness and bias in learning analytics. Further, these situated perspectives necessarily impact the tool and its capacity to be used in different circumstances over time and in different en vironments. Recognition of these constraints and their amelioration and emergence within an educational envi ronment is therefore a necessary challenge in scaling the function of an equitable learning analytics tool. Equity, fairness, and absence of bias of learning analytics there fore represents an ongoing design process that require continual (re)evaluation. 
Building on this, we argue that to effectively incorporate issues of equity, a more participatory approach to design and analysis is necessary [1]. Vakil, McKinney de Royston, Nasir, & Kirshner [66] argued that equitable learning re search and design centering race and power is advanced when participants and researchers share politicized trust, trust that “requires not only a personal working relation ship but also a political or racial solidarity” (p. 200). De signing effectively in this participatory way will require increasing methodological heterogeneity (see [29]). In particular, introducing rich qualitative analyses, such as qualitative language-based methodologies, into learning analytics work can add important contour to the larger studies of how people experience the environments being researched and designed through learning analytics (e.g., [47, 65]). Qualitative data and analysis may be helpful both for building into tools and for critically examining how they are used in situ. As Wise and Cui pointed out, at minimum, “Representative examples from the under lying data should be presented to help draw connections between the learning events as they occurred and their 
computational representations” [70, p. 1806]. Fine quali tative attunement to such examples can be a useful tool for helping learning analytics attend to political issues in learning. In particular, we would advocate for more inclusion of learner participation in the design and evalua tion of the fairness and efficacy of a learning analytics tool throughout and even after the design process. Learner participation can lead to broader representations of learn ing and have, largely, been an excluded voice in learning analytics research and practice [8]. 
In sum, we see several ways in which learning analytics researchers can attune to educational justice meaningfully: 
• Take a critical perspective to learning analytics. Such a perspective does not assume that learning analyt ics can solve every educational equity problem, but rather asks “Does learning analytics have a role to play in addressing this problem, and if so, how?” 
• Remember that educational data often represents the real, lived experiences of people. Learning analytics must always foreground the well-being of the learn ers involved. 
• In general, aim for fairness and limited bias in the design of algorithms. 
• Recognize that learning analytics interventions are part of educational systems, so a foundational ques tion for researchers and practitioners is how these interventions reinforce or challenge the oppression of minoritized groups in the context of those systems. In other words, “less biased” designs are not the same as “neutral” designs since learning analytics interven tions always take a position as supporting or oppos ing particular ways of participating in educational systems. 
• Involve a range of diverse perspectives throughout the design, implementation, and evaluation of learn ing analytics research and practice. 
• As discussed in the introduction, other chapters in this volume examine policy, ethics, and scale as they relate to learning analytics. In addition to the above recommendations, each of these areas (and their in tersections) are also places where learning analytics researchers and practitioners can contribute to ed ucational equity. Further, taking an equity lens by critically examining how policy, ethics, and scale can work towards the goal of educational justice is foun dational to ensuring that scholarship in these areas has a positive impact for a wide variety of learners. 
Finally, we argue that equity must be positioned as a cen tral concern in learning analytics. This will come with new challenges and require the development of new tools. However, centering equity will help ensure that learn ing analytics fulfills the promise of improving education, rather than making the existing inequitable structures of education function more efficiently. As the learning an alytics field continues to evolve, we hope to see more empirical work with an explicit equity orientation be ad vanced. 
CHAPTER 20: FAIRNESS, BIAS & EQUITY | PG 209
REFERENCES 
[1] Megan Bang. “Participatory design research and educational justice: Studying learning and relations within social change making”. In: Cognition and In struction 34.3 (2016). 
[2] Megan Bang. “Towards an ethic of decolonial trans ontologies in sociocultural theories of learning and development”. In: Power and privilege in the learning sciences: Critical and sociocultural theories of learning (2017), pp. 115–138. 
[3] David Beer. The Data Gaze: Capitalism, power and perception. Sage, 2018. 
[4] Phillip Bell and Katie Van Horne. “Designing learn ing environments for equitable disciplinary iden tification”. In: Journal of the Learning Sciences 26.3 (2017). 
[5] Gert Biesta. “Interrupting the politics of learning”. In: Power and Education 5.1 (2013), pp. 4–15. 
[6] Angela N. Booker, Shirin Vossoughi, and Paula K. Hooper. “Tensions and possibilities for political work in the learning sciences”. In: vol. 2. Interna tional Conference of the Learning Sciences (ICLS. International Society of the Learning Sciences, 2014. 
[7] Simon Buckingham Shum. “Critical Data Studies, Abstraction & Learning Analytics”. In: Journal of Learning Analytics 6.3 (2019), pp. 5–10. 
[8] Simon Buckingham Shum, Rebecca Ferguson, and Roberto Martinez-Maldonado. “Human-centred learning analytics”. In: Journal of Learning Analyt ics 6.2 (2019), pp. 1–9. 
[9] Aylin Caliskan, Joanna J Bryson, and Arvind Narayanan. “Semantics derived automatically from language corpora contain human-like biases”. In: Science 356.6334 (2017), pp. 183–186. 
[10] Bodong Chen and Haiyi Zhu. “Towards value sensitive learning analytics design”. In: Proceedings of the 9th International Conference on Learning An alytics & Knowledge. Mar. 2019, pp. 343–352. 
[11] Marika Cifor, Patricia Garcia, T. L. Cowan, Jasmine Rault, Tonia Sutherland, Anita Say Chan, Jennifer Rode, Anna Lauren Hoffmann, Niloufar Salehi, and Lisa Nakamura. Feminist Data Manifest-No. io. 2019. URL: https://www.manifestno.com/.. 
[12] Michael Cole. Cultural psychology: A once and future discipline. Harvard University Press, 1996. 
[13] Candace Cortiella and Sheldon H. Horowitz. The state of learning disabilities: Facts, trends and emerg ing Issues. New York: National Center for Learning Disabilities, 2014. 
[14] Joe Curnow. “Towards a Radical Theory of Learn ing: Prefiguration as Legitimate Peripheral Partic ipation”. In: The Radicalization of Pedagogy. NY, NY: Rowman and Littlefield, 2016, pp. 27–49. 
PG 210 | HANDBOOK OF LEARNING ANALYTICS
[15] Mollie Dollinger, Danny Liu, Natasha Arthars, and Jason Lodge. “Working together in learning analyt ics towards the co-creation of value”. In: Journal of Learning Analytics 6.2 (2019), pp. 10–26. 
[16] Shayan Doroudi and Emma Brunskill. “Fairer but not fair enough on the equitability of knowledge tracing”. In: Proceedings of the 9th International Conference on Learning Analytics & Knowledge. Mar. 2019, pp. 335–339. 
[17] Frederick Erickson, Rishi Bagrodia, Alison Cook Sather, Manuel Espinoza, Susan Jurow, and Jeffrey J. Schultz. “Students’ experience of school curricu lum”. In: The Sage handbook of curriculum and instruction. London: Sage, 2008, pp. 198–218. 
[18] Indigo Esmonde and Angela N. Booker. Power and privilege in the learning sciences: Critical and sociocul tural theories of learning. New York, NY: Routledge, 2017. 
[19] Manuel Luis Espinoza and Shirin Vossoughi. “Per ceiving learning anew: Social interaction, dignity, and educational rights”. In: Harvard Educational Re view 84.3 (2014), pp. 285–313. 
[20] Alfred Essa. “Is Data Dark? Lessons from Borges’s “Funes the Memorius””. In: Journal of Learning Ana lytics 6.3 (2019), pp. 35–42. 
[21] Virginia Eubanks. Automating inequality: How high tech tools profile, police, and punish the poor. St. Mar tin’s Press, 2018. 
[22] Rebecca Ferguson. “Ethical challenges for learning analytics”. In: Journal of Learning Analytics 6.3 (2019), pp. 25–30. 
[23] Paulo Freire. Pedagogy of the oppressed. New York, NY: Herder & Herder, 1972. 
[24] Sorelle A. Friedler, Carlos Scheidegger, Suresh Venkatasubramanian, Sonam Choudhary, Evan P. Hamilton, and Derek Roth. “A comparative study of fairness-enhancing interventions in machine learn ing”. In: Proceedings of the Conference on Fair ness, Accountability, and Transparency. Jan. 2019, pp. 329–338. 
[25] Josh Gardner, Christopher Brooks, and Ryan S. J. d. Baker. “Evaluating the fairness of predictive student models through slicing analysis”. In: Proceedings of the 9th International Conference on Learning An alytics & Knowledge. Mar. 2019, pp. 225–234. 
[26] Norma González, Luis C. Moll, and Cathy Amanti. Funds of knowledge: Theorizing practices in households, communities, and classrooms. Routledge, 2006. 
[27] Kris D. Gutiérrez and Barbara Rogoff. “Cultural ways of learning: Individual traits or repertoires of practice”. In: Educational researcher 32.5 (2003), pp. 19–25. 
[28] Victoria Hand and Melissa Gresalfi. “The joint ac complishment of identity”. In: Educational Psycholo gist 50.3 (2015), pp. 190–203. 
[29] Heisawn Jeong, Cindy E Hmelo-Silver, and Yawen Yu. “An examination of CSCL methodological prac tices and the influence of theoretical frameworks 2005–2009”. In: International Journal of Computer Supported Collaborative Learning 9.3 (2014), pp. 305– 334. 
[30] Kyle M.L. Jones and Chase McCoy. “Ethics in Praxis: Socio-technical integration research in learning an alytics”. In: Companion Proceedings of the 9th In ternational Conference on Learning Analytics and Knowledge. Mar. 2019, pp. 5–13. 
[31] Gloria Ladson-Billings. “From the achievement gap to the education debt: Understanding achievement in US schools”. In: Educational researcher 35.7 (2006), pp. 3–12. 
[32] Gloria Ladson-Billings. “Toward a theory of cultur ally relevant pedagogy”. In: American educational research journal 32.3 (1995), pp. 465–491. 
[33] Politics Learning Writing Collective. “The Learn ing Sciences in a new era of US nationalism”. In: Cognition & Instruction 35.2 (2017), pp. 91–102. 
[34] Joel McFarland, Bill Hussar, Cristobal De Brey, Tom Snyder, Xiaolei Wang, Sidney Wilkinson-Flicker, Semhar Gebrekristos, Jijun Zhang, Amy Rathbun, and Amy Barmer. The Condition of education 2017. <p>Retrieved [date] from</p>. Washington, DC: U.S. Department of Education, 2017. URL: https: //nces.ed.gov/pubsearch/pubsinfo.asp? pubid=2017144.. 
[35] Maxine McKinney de Royston and Tesha Sengupta Irving. “Another step forward: engaging the polit ical in learning”. In: Cognition and Instruction 37.3 (2019), pp. 277–284. 
[36] Jacob McWilliams. “Queering participatory design research”. In: Cognition and Instruction 34.3 (2016), pp. 259–274. 
[37] Michael Meaney and Tom Fikes. “Early-adopter Iter ation Bias and Research-praxis Bias in the Learning Analytics Ecosystem”. In: Companion Proceedings of the 9th International Conference on Learning An alytics and Knowledge. Mar. 2019, pp. 14–19. 
[38] Douglas L Medin and Megan Bang. Who’s asking? Native science, western science, and science education. MIT Press, 2014. 
[39] H. Richard Milner and Judson C. Laughter. “But good intentions are not enough: Preparing teachers to center race and poverty”. In: The Urban Review 47.2 (2015), pp. 341–363. 
[40] Na’ilah Suad Nasir and Jamal Cooks. “Becoming a hurdler: How learning settings afford identities”. In: Anthropology & Education Quarterly 40.1 (2009), pp. 41–61. 
[41] Na’ilah Suad Nasir and Victoria M. Hand. “Explor ing sociocultural perspectives on race, culture, and learning”. In: Review of Educational Research 76.4 (2006), pp. 449–475. 
[42] United Nations. Convention on the rights of the child. New York, UN, 1989. 
[43] United Nations. Universal declaration of human rights. New York, UN, 1948. 
[44] Safiya Umoja Noble. Algorithms of oppression: How search engines reinforce racism. NYU Press, 2018. 
[45] Cathy O’Neill. Weapons of math destruction: How big data increases inequality and threatens democracy. Broadway Books, 2016. 
[46] Django Paris. “Culturally sustaining pedagogy: A needed change in stance, terminology, and practice”. In: Educational Researcher 41.3 (2012), pp. 93–97. 
[47] Trena M. Paulus and Alyssa F. Wise. Looking for in sight, transformation, and learning in online talk. New York: Routledge, 2019. 
[48] Carlo Perrotta and Ben Williamson. “The social life of Learning Analytics: cluster analysis and the ‘per formance’of algorithmic education”. In: Learning, Media and Technology 43.1 (2018), pp. 3–16. 
[49] Thomas M. Philip, Megan Bang, and Kara Jackson. “Articulating the “how,” the “for what,” the “for whom,” and the “with whom” in concert: A call to broaden the benchmarks of our scholarship”. In: Cognition and Instruction 36.2 (2018), pp. 83–88. 
[50] Paul Prinsloo. “A social cartography of analytics in education as performative politics”. In: British Jour nal of Educational Technology 50.6 (2019), pp. 2810– 2823. 
[51] Paul Prinsloo. “Commentary on Neil Selwyn’s LAK18 keynote address”. In: Journal of Learning An alytics 6.3 (2019), pp. 20–24. 
[52] Paul Prinsloo and Sharon Slade. “Educational triage in open distance learning: Walking a moral tightrope”. In: International Review of Research in Open and Distributed Learning 15.4 (2014), pp. 306– 331. 
[53] Daniel L. Reinholz and Niral Shah. “Equity ana lytics: A methodological approach for quantifying participation patterns in mathematics classroom dis course”. In: Journal for Research in Mathematics Edu cation 49.2 (2018), pp. 140–177. 
[54] Rashida Richardson, Jason M Schultz, and Kate Crawford. “Dirty data, bad predictions: How civil rights violations impact police data, predictive polic ing systems, and justice”. In: New York University Law Review Online (2019). 
[55] Rashida Richardson, Jason M. Schultz, and Kate Crawford. “Ethical Considerations in Adopting a University and System-Wide Approach to Data and Learning Analytics”. In: Big Data and Learning An alytics in Higher Education. Cham: Springer, 2017. 
[56] Carolyn P. Rosé. “Learning analytics in the learning sciences”. In: International Handbook of the Learn ing Sciences. Routledge, 2018. 
CHAPTER 20: FAIRNESS, BIAS & EQUITY | PG 211
[57] Carolyn P. Rosé. “Monolith, Multiplicity or Multi vocality: What do we stand for and where do we go from here?” In: Journal of Learning Analytics 6.3 (2019), pp. 31–34. 
[58] Ann S. Rosebery, Mark Ogonowski, Mary DiSchino, and Beth Warren. “The coat traps all your body heat”: Heterogeneity as fundamental to learning”. In: Journal of the Learning Sciences 19.3 (2010), pp. 322–357. 
[59] Andrew D Selbst, Danah Boyd, Sorelle A Friedler, Suresh Venkatasubramanian, and Janet Vertesi. “Fairness and abstraction in sociotechnical systems”. In: Proceedings of the Conference on Fairness, Ac countability, and Transparency. Jan. 2019, pp. 59– 68. 
[60] Neil Selwyn. “What’s the Problem with Learn ing Analytics?” In: Journal of Learning Analytics 6.3 (2019), pp. 11–19. 
[61] Cyndy R. Snyder, Niral Shah, and Kihana Miraya Ross. “Racial storylines and implications for learn ing”. In: Human Development 55.5-6 (2012), pp. 285– 301. 
[62] Stephanie D. Teasley. Learning analytics: where infor mation science and the learning sciences meet. Informa tion and Learning Sciences, 2019. 
[63] Yi-Shan Tsai, Carlo Perrotta, and Dragan Gaševi´c. “Empowering learners with personalised learning approaches? Agency, equity and transparency in the context of learning analytics”. In: Assessment & Evaluation in Higher Education (2019), pp. 1–14. 
[64] Suraj Uttamchandani. “Equity in the learning sci ences: Recent themes and pathways”. In: Proceed ings of the 13th international conference of the learn ing sciences. ISLS, 2018, pp. 1799–1806. 
[65] Suraj Uttamchandani and Jessica N. Lester. “Lan guage - Qualitative approaches to language in CSCL”. In: International Handbook of Computer Supported Collaborative Learning. in press. Springer. 
[66] Sepehr Vakil, Maxine McKinney de Royston, Na’ilah Suad Nasir, and Ben Kirshner. “Rethinking race and power in design-based research: Reflec tions from the field”. In: Cognition and Instruction 34.3 (2016), pp. 194–209. 
[67] Tanner Vea. “The ethical sensations of im-mediacy: Embodiment and multiple literacies in animal rights activists’ learning with media technologies”. In: British Journal of Educational Technology 50.4 (2019), pp. 1589–1602. 
[68] Shirin Vossoughi and Kris D. Gutiérrez. “Critical pedagogy and sociocultural theories”. In: Power and privilege in the learning sciences: Critical and sociocultural theories of learning. New York, NY: Routledge, 2017. 
[69] Audrey Watters. The 100 worst ed-tech debacles of the decade. 2019. URL: http://hackeducation. com/2019/12/31/what-a-shitshow. 
PG 212 | HANDBOOK OF LEARNING ANALYTICS
[70] Alyssa F. Wise and Yi Cui. “Envisioning a learning analytics for the learning sciences”. In: Proceedings of the 13th international conference of the learning sciences. ISLS, 2018, pp. 1799–1806.